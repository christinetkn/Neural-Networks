{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  $1^{η}$ Εργαστηριακή Άσκηση Νευρωνικών Δικτύων και Ευφυών Υπολογιστικών Συστημάτων\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Επιβλεπόμενη Μάθηση: Ταξινόμηση "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ομάδα 11 (Datasets U11\tK07)\n",
    "- Καράμπελα Θεοφανία ΑΜ: <font color='dodgerblue'>03117091</font>\n",
    "- Τσακανίκα Χριστίνα ΑΜ: <font color='dodgerblue'>03117012</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Μέρος 1. UCI  dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Σύντομη παρουσίαση του dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy<1.23.0,>=1.16.5 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from scipy) (1.19.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scipy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eισαγωγή dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Quality Assessment - Digital Colposcopy/all.csv\", skiprows=[99,197,290])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To dataset αφορά τον υποκειμενικό ποιοτικό έλεγχο ψηφιακών κολποσκοπήσεων."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Για το συγκεκριμένο dataset δεν χρειάστηκαν μετατροπές στα αρχεία plain text, παραμόνο να συνενώσουμε τα επιμέρους αρχεία .csv σε ένα ενιαίο."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Συνολικά έχουμε:\n",
    "   - _287 δείγματα_\n",
    "   - _69 χαρακτηριστικά εκ των οποίων τα 62 ειναι χαρακτηριστικά πρόβλεψης και τα 7 ειναι target variables_\n",
    "   - _Δεν υπάρχουν μη διατεταγμένα χαρακτηριστικά_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Σε κάθε στήλη εμφανίζεται ως τίτλος το όνομα του χαρακτηριστικού. Οι γραμμές δεν ειναι αριθμημένες."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Οι ετικέτες των κλάσεων αποτυπώνονται ως 0 και 1 και βρίσκονται στην τελευταία κολώνα με τίτλο consensus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Με την εντολή: \n",
    "\"findstr \"NaN\" all.csv | find \"NaN\" /c\" στο command line καθώς και \" _print(data.isna().sum()) & print(data.isnull().sum())_\" \n",
    "διαπιστώνουμε πως δεν υπάρχουν απουσιάζουσες τιμές."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Το dataset αποτελείται από δύο κλάσεις 1 για το good και 0 για το bad. Για τα ποσοστά των δειγμάτων επί του συνόλου έχουμε ότι η κλάση 1 αποτελεί το 75.26% του συνόλου, ενώ η κλάση 0 αποτελεί το 24.74% αυτού. Εφόσον, η πρώτη κλάση εμφανίζεται τρεις φορές συχνότερα της δεύτερης, το dataset δεν είναι ισορροπημένο.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the percentage os zeros is:  24.738675958188153 %\n",
      "the percentage os ones is:  75.26132404181185 %\n",
      "Ones are 3.0422535211267605 times more than zeros\n"
     ]
    }
   ],
   "source": [
    "zeros = data[data.consensus == 0].shape[0]\n",
    "ones = data[data.consensus == 1].shape[0]\n",
    "print(\"the percentage os zeros is: \", (zeros/(zeros+ones))*100, '%')\n",
    "print(\"the percentage os ones is: \", (ones/(zeros+ones))*100, '%')\n",
    "print(\"Ones are\", ones/zeros, \"times more than zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Προετοιμασία"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Θέτουμε το _test_size = 0.3_ προκειμένου να εξασφαλίσουμε  test set ισο με το 30% των δειγμάτων. Δεν υπάρχουν απουσιάζουσες τιμές ούτε και κατηγορικά ή μη διατεταγμένα χαρακτηριστικά."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y (Features and Labels)\n",
    "X = np.array(data.drop([\"experts::0\",\"experts::1\",\"experts::2\",\"experts::3\",\"experts::4\",\"experts::5\",\"consensus\"], axis = 1))\n",
    "y = np.array(data[\"consensus\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ταξινόμηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_val(classifier, X, y):\n",
    "    acc = cross_val_score(classifier, X, y, cv=10)\n",
    "    f1 = cross_val_score(classifier, X, y, cv=10 , scoring='f1')\n",
    "    print(\"The mean accuracy for \"+ str(classifier)[:-2]+\" is: \", acc.mean(), \"\\n\", \"The F1-score for \"+ str(classifier)[:-2]+\" is:\", f1.mean(),  '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eπίδοση οut-of-the-box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for DummyClassifier is:  0.775 \n",
      " The F1-score for DummyClassifier is: 0.8730158730158729 \n",
      "\n",
      "The mean accuracy for GaussianNB is:  0.755 \n",
      " The F1-score for GaussianNB is: 0.8383939192748817 \n",
      "\n",
      "The mean accuracy for KNeighborsClassifier is:  0.78 \n",
      " The F1-score for KNeighborsClassifier is: 0.8699046133604957 \n",
      "\n",
      "The mean accuracy for LogisticRegression is:  0.7750000000000001 \n",
      " The F1-score for LogisticRegression is: 0.8657151619200955 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "perform_cross_val(DummyClassifier(), X_train,y_train)\n",
    "perform_cross_val(GaussianNB(), X_train,y_train)\n",
    "perform_cross_val(KNeighborsClassifier(), X_train,y_train)\n",
    "perform_cross_val(LogisticRegression(), X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier | Accuracy | F1-score |\n",
    "| --- | --- | --- |\n",
    "| Dummy | 0.775 | 0.873 |\n",
    "| --- | --- | --- |\n",
    "| Gaussian Naive Bayes | 0.755  | 0.838 |\n",
    "| --- | --- | --- |\n",
    "| K Neighbors | 0.780 | 0.870 |\n",
    "| --- | --- | --- |\n",
    "| Logistic Regression | 0.775 | 0.866 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "res = {'Dummy':(0.775, 0.873), 'Gaussian Naive Bayes':(0.860, 0.913), 'K Neighbors':(0.780, 0.870),\n",
    "        'Logistic Regression':(0.815, 0.898)}\n",
    "\n",
    "\n",
    "classifiers = list(res.keys())\n",
    "values = np.array(list(res.values()))\n",
    "f1score = values[:,1]   \n",
    "accur =  values[:,0]\n",
    "\n",
    "#print(f1score, accur)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.bar(classifiers, accur, color ='paleturquoise', width = 0.4)\n",
    "ax2.set_title('F1-score')\n",
    "ax2.bar(classifiers, f1score, color ='khaki',width = 0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Σύμφωνα με τα παραπάνω, ο Gaussian classifier παρουσιάζει τις υψηλότερες επιδόσεις και στις δύο μετρικές. H υπόθεση πως τα χαρακτηριστικά κάθε δείγματος είναι ανεξάρτητα μεταξύ τους, επιταχύνουν το χρόνο υπολογισμού, σημειώνοντας υψηλή ακρίβεια. Στην προκειμένη περίπτωση, όπου ορισμένα χαρακτηριστικά παρουσίαζαν πράγματι ανεξαρτησία, ο αλγόριθμος καθίσταται επιπλέον αποδοτικός. Ακολουθεί ο Logistic Regression, K Neighbors και τέλος ο Dummy.\n",
    "Παρατηρούμε επιπλέον, πως τα F1-scores ειναι υψηλότερα των αντίστοιχων accuracies, διότι η μετρική αυτή αποδίδει καλύτερα όταν το dataset ειναι imbalanced. Συγκεκριμένα, ο αρμονικός μέσος όρος των Precision και Recall μετριάζει τα δείγματα που δεν κατηγοριοποιήθηκαν σωστά."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Βελτιστοποίηση"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from imbalanced-learn) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from imbalanced-learn) (1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from imbalanced-learn) (1.19.4)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (3.0.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.8.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Προεπεξεργασία"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def perform_preprocessing(classifier, X_train,X_test, y_test, y_train):\n",
    "        \n",
    "    selector = VarianceThreshold()\n",
    "    train_reduced = selector.fit_transform(X_train)\n",
    "    #mask = selector.get_support()\n",
    "    #y_reduced = y[:,mask]\n",
    "    test_reduced = selector.transform(X_test)\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(train_reduced)\n",
    "    train_scaled = scaler.transform(train_reduced)\n",
    "    test_scaled = scaler.transform(test_reduced)\n",
    "\n",
    "    ros = RandomOverSampler()\n",
    "    #print(\"the shapes are: \", train_scaled.shape,len(y_train))\n",
    "    #mlb = MultiLabelBinarizer().fit(y)\n",
    "    train_resampled, trainTargets_resampled = ros.fit_resample(train_scaled,y_train)\n",
    "\n",
    "    n = 25\n",
    "    pca = PCA(n_components=n)\n",
    "    trainPCA = pca.fit_transform(train_resampled)\n",
    "    testPCA = pca.transform(test_scaled)\n",
    "    \n",
    "    classifier.fit(trainPCA, trainTargets_resampled)\n",
    "    preds = classifier.predict(testPCA)\n",
    "    #print(len(y_test),len(preds))\n",
    "    print(classification_report(y_test, preds))\n",
    "    #return X_transformed\n",
    "    acc = cross_val_score(classifier, trainPCA, trainTargets_resampled, cv=10)\n",
    "    #acc = acc.mean()\n",
    "    f1 = cross_val_score(classifier, trainPCA, trainTargets_resampled, cv=10 , scoring='f1')\n",
    "    print(\"The mean accuracy for \"+ str(classifier)[:-2]+\" is: \", acc.mean(), \"\\n\", \"The F1-score for \"+ str(classifier)[:-2]+\" is:\", f1.mean(),  '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.30      1.00      0.46        26\n",
      "         1.0       0.00      0.00      0.00        61\n",
      "\n",
      "    accuracy                           0.30        87\n",
      "   macro avg       0.15      0.50      0.23        87\n",
      "weighted avg       0.09      0.30      0.14        87\n",
      "\n",
      "The mean accuracy for DummyClassifier is:  0.4838709677419356 \n",
      " The F1-score for DummyClassifier is: 0.32608695652173914 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.35      0.35      0.35        26\n",
      "         1.0       0.72      0.72      0.72        61\n",
      "\n",
      "    accuracy                           0.61        87\n",
      "   macro avg       0.53      0.53      0.53        87\n",
      "weighted avg       0.61      0.61      0.61        87\n",
      "\n",
      "The mean accuracy for GaussianNB is:  0.7612903225806452 \n",
      " The F1-score for GaussianNB is: 0.8484651064726966 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.38      0.35      0.36        26\n",
      "         1.0       0.73      0.75      0.74        61\n",
      "\n",
      "    accuracy                           0.63        87\n",
      "   macro avg       0.55      0.55      0.55        87\n",
      "weighted avg       0.62      0.63      0.63        87\n",
      "\n",
      "The mean accuracy for KNeighborsClassifier is:  0.8129032258064516 \n",
      " The F1-score for KNeighborsClassifier is: 0.8936626199979435 \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.58      0.54        26\n",
      "         1.0       0.81      0.75      0.78        61\n",
      "\n",
      "    accuracy                           0.70        87\n",
      "   macro avg       0.65      0.67      0.66        87\n",
      "weighted avg       0.72      0.70      0.71        87\n",
      "\n",
      "The mean accuracy for LogisticRegression is:  0.7761290322580645 \n",
      " The F1-score for LogisticRegression is: 0.8043703719899492 \n"
     ]
    }
   ],
   "source": [
    "perform_preprocessing(DummyClassifier(), X_train,X_test, y_test, y_train)\n",
    "perform_preprocessing(GaussianNB(), X_train,X_test, y_test, y_train)\n",
    "perform_preprocessing(KNeighborsClassifier(), X_train,X_test, y_test, y_train)\n",
    "perform_preprocessing(LogisticRegression(), X_train,X_test, y_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.decomposition import PCA   \n",
    "\n",
    "def define_pipeline(classifier,X,y):\n",
    "    selector = VarianceThreshold()\n",
    "    scaler = StandardScaler()\n",
    "    ros = RandomOverSampler()\n",
    "    pca = PCA()\n",
    "    pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca', pca), ('classifier', classifier)])\n",
    "    \n",
    "    acc = cross_val_score(classifier, X, y, cv=10) #X_train, y_train\n",
    "    f1 = cross_val_score(classifier, X, y, cv=10 , scoring='f1') #X_train, y_train\n",
    "    print(\"The mean accuracy for \"+ str(classifier)[:-2]+\" is: \", acc.mean(), \"\\n\", \"The F1-score for \"+ str(classifier)[:-2]+\" is:\", f1.mean(),  '\\n') \n",
    "    \n",
    "    return selector, scaler, ros, pca, pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for DummyClassifier is:  0.775 \n",
      " The F1-score for DummyClassifier is: 0.8730158730158729 \n",
      "\n",
      "The mean accuracy for GaussianNB is:  0.785 \n",
      " The F1-score for GaussianNB is: 0.8583939192748817 \n",
      "\n",
      "The mean accuracy for KNeighborsClassifier is:  0.815 \n",
      " The F1-score for KNeighborsClassifier is: 0.8699046133604957 \n",
      "\n",
      "The mean accuracy for LogisticRegression is:  0.7780000000000001 \n",
      " The F1-score for LogisticRegression is: 0.8657151619200955 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "define_pipeline(DummyClassifier(), X_train,y_train)\n",
    "define_pipeline(GaussianNB(), X_train,y_train)\n",
    "define_pipeline(KNeighborsClassifier(), X_train,y_train)\n",
    "define_pipeline(LogisticRegression(), X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Eύρεση βέλτιστων υπερμαραμέτρων με grid search & cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aρχικά με την εντολή \"print(np.max(X_train.var(axis=0)))\" ελέγχουμε που κυμαίνεται η διακύμανση των train δεδομένων, προκειμένου να καθορίσουμε στην συνέχεια τον variance threshold πίνακα. Παρακάτω, παρουσιάζονται τα scores και οι καλύτερες παράμετροι για κάθε μετρική και κάθε μοντέλο αντίστοιχα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795\n",
      "{'dummy__strategy': 'stratified', 'pca__n_components': 14, 'selector__threshold': 1200}\n",
      "0.892630485733934\n",
      "{'dummy__strategy': 'uniform', 'pca__n_components': 10, 'selector__threshold': 700}\n"
     ]
    }
   ],
   "source": [
    "DummyClassifier().get_params()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vthreshold = [0,1,10,20,30,50,80,90, 100,200, 300, 400, 500, 600, 700, 800,900, 1000, 1100, 1200, 1300] \n",
    "n_components = [10, 11,12,13,14,15,16,17, 23,24,25,26,27,28]\n",
    "\n",
    "selector, scaler, ros, pca, _ = define_pipeline(DummyClassifier(), X_train,y_train)\n",
    "\n",
    "dummy_pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca', pca), ('dummy', DummyClassifier())], memory = 'tmp')\n",
    "dummy_param_grid = dict(selector__threshold=vthreshold, pca__n_components=n_components, dummy__strategy=[\"stratified\", \"most_frequent\", \"prior\", \"uniform\", \"constant\"])\n",
    "\n",
    "dummy_grid_acc = GridSearchCV(dummy_pipe, dummy_param_grid, cv=10, scoring='accuracy').fit(X_train, y_train)\n",
    "dummy_grid_f1 = GridSearchCV(dummy_pipe, dummy_param_grid, cv=10, scoring='f1').fit(X_train, y_train)\n",
    "\n",
    "print(dummy_grid_acc.best_score_)\n",
    "print(dummy_grid_acc.best_params_)\n",
    "\n",
    "print(dummy_grid_f1.best_score_)\n",
    "print(dummy_grid_f1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799\n",
      "{'gaussian__var_smoothing': 1e-09, 'pca__n_components': 14, 'selector__threshold': 0}\n",
      "0.8792332431225318\n",
      "{'gaussian__var_smoothing': 1e-09, 'pca__n_components': 14, 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "GaussianNB().get_params()\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vthreshold = [0,1,10,20,30,50,80,90, 100,200, 300, 400, 500, 600, 700, 800,900, 1000, 1100, 1200, 1300] \n",
    "n_components = [10, 11,12,13,14,15,16,17, 23,24,25,26,27,28]\n",
    "\n",
    "selector, scaler, ros, pca, _ = define_pipeline(GaussianNB(), X_train,y_train)\n",
    "\n",
    "gaussian_pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca', pca), ('gaussian', GaussianNB())], memory = 'tmp')\n",
    "gaussian_param_grid = dict( selector__threshold=vthreshold, pca__n_components=n_components, gaussian__var_smoothing=[1e-09,1e-08,1e-10,1e-11])\n",
    "\n",
    "gaussian_grid_acc = GridSearchCV(gaussian_pipe, gaussian_param_grid, cv=10, scoring='accuracy').fit(X_train, y_train)\n",
    "gaussian_grid_f1 = GridSearchCV(gaussian_pipe, gaussian_param_grid, cv=10, scoring='f1').fit(X_train, y_train)\n",
    "\n",
    "print(gaussian_grid_acc.best_score_)\n",
    "print(gaussian_grid_acc.best_params_)\n",
    "\n",
    "print(gaussian_grid_f1.best_score_)\n",
    "print(gaussian_grid_f1.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.822\n",
      "{'neighbors__n_neighbors': 29, 'neighbors__weights': 'uniform', 'pca__n_components': 17, 'selector__threshold': 0}\n",
      "0.8657122013028085\n",
      "{'neighbors__n_neighbors': 30, 'neighbors__weights': 'distance', 'pca__n_components': 16, 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vthreshold = [0,1,10,20,30,50,80,90, 100,200, 300, 400, 500, 600, 700, 800,900, 1000, 1100, 1200, 1300] \n",
    "n_components = [10, 11,12,13,14,15,16,17, 23,24,25,26,27,28]\n",
    "\n",
    "selector, scaler, ros, pca, _ = define_pipeline(KNeighborsClassifier(), X_train,y_train)\n",
    "\n",
    "neighbors_pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca', pca), ('neighbors', KNeighborsClassifier())], memory = 'tmp')\n",
    "neighbors_param_grid = dict( selector__threshold=vthreshold, pca__n_components=n_components, neighbors__n_neighbors=list(range(1, 31)), neighbors__weights=['uniform', 'distance'])\n",
    "\n",
    "neighbors_grid_acc = GridSearchCV(neighbors_pipe, neighbors_param_grid, cv=10, scoring='accuracy').fit(X_train, y_train)\n",
    "neighbors_grid_f1 = GridSearchCV(neighbors_pipe, neighbors_param_grid, cv=10, scoring='f1').fit(X_train, y_train)\n",
    "\n",
    "print(neighbors_grid_acc.best_score_)\n",
    "print(neighbors_grid_acc.best_params_)\n",
    "\n",
    "print(neighbors_grid_f1.best_score_)\n",
    "print(neighbors_grid_f1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7950000000000001\n",
      "{'logistic__C': 0.1, 'logistic__class_weight': 'balanced', 'logistic__penalty': 'l2', 'logistic__tol': 1e-19, 'pca__n_components': 20, 'selector__threshold': 0}\n",
      "0.8887234687526572\n",
      "{'logistic__C': 0.1, 'logistic__class_weight': 'balanced', 'logistic__penalty': 'l2', 'logistic__tol': 1e-19, 'pca__n_components': 20, 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "vthreshold = [-500,-100,-90,-1,0,1] \n",
    "n_components = [1,2,5,9,10,11,12,13,14,20]\n",
    "\n",
    "selector, scaler, ros, pca, _ = define_pipeline(LogisticRegression(), X_train,y_train)\n",
    "\n",
    "logistic_pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca', pca), ('logistic', LogisticRegression())], memory = 'tmp')\n",
    "logistic_param_grid = dict( selector__threshold=vthreshold, pca__n_components=n_components, logistic__C = [0.0001,0.001,0.1,1.0, 10.0, 100.0, 1000.0], logistic__class_weight = [\"balanced\",\"None\"],\n",
    "                           logistic__penalty=[\"l1\",\"l2\",\"none\",\"elasticnet\"],logistic__tol = [1e-19,1e-18,1e-17,1e-16,1e-15])\n",
    "\n",
    "logistic_grid_acc = GridSearchCV(logistic_pipe, logistic_param_grid, cv=10, scoring='accuracy').fit(X_train, y_train)\n",
    "logistic_grid_f1 = GridSearchCV(logistic_pipe, logistic_param_grid, cv=10, scoring='f1').fit(X_train, y_train)\n",
    "\n",
    "print(logistic_grid_acc.best_score_)\n",
    "print(logistic_grid_acc.best_params_)\n",
    "\n",
    "print(logistic_grid_f1.best_score_)\n",
    "print(logistic_grid_f1.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eκπαιδεύουμε το καλύτερο μοντέλο κάθε ταξινομητή, στο σύνολο του train set και εκτιμούμε την επίδοσή του στο test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Training time: 0.01\n",
      "Best Dummy Classifier model accuracy:  0.47126436781609193\n",
      "Dummy Classifier Test time: 0.001\n",
      "\n",
      "\n",
      "Guassian Classifier Training time: 0.014\n",
      "Best Gaussian Naive Bayes Classifier model accuracy:  0.7011494252873564\n",
      "Gaussian Classifier Test time: 0.008\n",
      "\n",
      "\n",
      "K Neighbors Classifier Training time: 0.008\n",
      "Best K Neighbors Classifier model accuracy:  0.7471264367816092\n",
      "K Neighbors Classifier Test time: 0.008\n",
      "\n",
      "\n",
      "Logistic Classifier Training time: 0.024\n",
      "Best Logistic Regression model accuracy:  0.6781609195402298\n",
      "Logistic Classifier Test time: 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#uniform', 'pca__n_components': 24, 'selector__threshold': 500\n",
    "def best_model(n_components,threshold, classifier):\n",
    "    selector = VarianceThreshold(threshold)\n",
    "    scaler = StandardScaler()\n",
    "    ros = RandomOverSampler()\n",
    "    pca = PCA(n_components)\n",
    "    pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca', pca), ('classifier', classifier)])\n",
    "    return pipe\n",
    "\n",
    "t0=time.time()\n",
    "best_dummy = best_model(n_components = 14,threshold=1200, classifier = DummyClassifier(strategy = 'stratified'))\n",
    "best_dummy.fit(X_train,y_train)\n",
    "print(\"Dummy Classifier Training time:\", round(time.time()-t0, 3))\n",
    "t1=time.time()\n",
    "print(\"Best Dummy Classifier model accuracy: \", best_dummy.score(X_test,y_test))\n",
    "print(\"Dummy Classifier Test time:\", round(time.time()-t1, 3))\n",
    "print('\\n')\n",
    "\n",
    "#{'gaussian__var_smoothing': 1e-09, 'pca__n_components': 13, 'selector__threshold': 0}\n",
    "t2=time.time()\n",
    "best_gaussian = best_model(n_components = 14,threshold=0, classifier = GaussianNB(var_smoothing = 1e-09))\n",
    "best_gaussian.fit(X_train,y_train)\n",
    "print(\"Guassian Classifier Training time:\", round(time.time()-t2, 3))\n",
    "t3=time.time()\n",
    "print(\"Best Gaussian Naive Bayes Classifier model accuracy: \",best_gaussian.score(X_test,y_test))\n",
    "print(\"Gaussian Classifier Test time:\", round(time.time()-t3, 3))\n",
    "print('\\n')\n",
    "\n",
    "#neighbors__n_neighbors': 1, 'neighbors__weights': 'uniform', 'pca__n_components': 9,'selector__threshold': 0} 0.\n",
    "t4=time.time()\n",
    "best_neighbors = best_model(n_components = 17,threshold=0, classifier = KNeighborsClassifier(n_neighbors=29,weights='uniform' ))\n",
    "best_neighbors.fit(X_train,y_train)\n",
    "print(\"K Neighbors Classifier Training time:\", round(time.time()-t4, 3))\n",
    "t5=time.time()\n",
    "print(\"Best K Neighbors Classifier model accuracy: \",best_neighbors.score(X_test,y_test))\n",
    "print(\"K Neighbors Classifier Test time:\", round(time.time()-t5, 3))\n",
    "print('\\n')\n",
    "\n",
    "#logistic__C': 1.0, 'logistic__class_weight': 'balanced', 'logistic__penalty': 'l2', 'logistic__tol': 1e-19, 'pca__n_components': 14\n",
    "t6=time.time()\n",
    "best_logistic =  best_model(n_components = 20,threshold=0, classifier = LogisticRegression(C=1.0, class_weight='balanced', penalty='l2', tol=1e-19 ))\n",
    "best_logistic.fit(X_train,y_train)\n",
    "print(\"Logistic Classifier Training time:\", round(time.time()-t6, 3))\n",
    "t7=time.time()\n",
    "print(\"Best Logistic Regression model accuracy: \", best_logistic.score(X_test,y_test))\n",
    "print(\"Logistic Classifier Test time:\", round(time.time()-t7, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aποτελέσματα και συμπεράσματα"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "| Classifier | Accuracy | F1-score | otb Accuracy |otb F1-score |Train Time | Test Time |Accuracy in test set|\n",
    "| --- | --- | --- |--- | --- |--- | --- |--- |\n",
    "| Dummy | 0.795 | 0.893 | +0.002| +0.002 |0.010 | 0.001 |0.471 |\n",
    "| --- | --- | --- |--- | --- |--- | --- |--- |\n",
    "| Gaussian Naive Bayes | 0.799 | 0.879 |+0.044 |+0.041 |0.014| 0.008 |0.701 |\n",
    "| --- | --- | --- |--- | --- |--- | --- |--- |\n",
    "| K Neighbors | 0.822 | 0.866 |+0.0800 | +0.042 |-0.004 | 0.008 |0.747 |\n",
    "| --- | --- | --- |--- | --- |--- | --- |--- |\n",
    "| Logistic Regression | 0.795 | 0.889 |+0.020 |+0.023 |0.024 | 0.008 |0.678 |\n",
    "\n",
    "<br>\n",
    "otb Accuracy:  Η διαφορά συγκριτικά με το οut of the box μοντέλο, κατά τη μετρική  accuracy.\n",
    "<br>\n",
    "otb F1-score : H διαφορά συγκριτικά με το out of the box μοντέλο, κατά τη μετρική F1-score.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Bar plot σύγκρισης"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colors1 = ['paleturquoise','khaki','red' ]\n",
    "colors2 = ['cyan','coral','hotpink' ]\n",
    "\n",
    "res1 = {'D1':(0.775),'D2':(0.795),\"diff1\":(0.002), 'GNB1':(0.755),'GNB2':(0.799), \n",
    "        \"diff2\":(0.044),'KN1':(0.7800),'KN2':(0.866),\"diff3\":(0.0800),\n",
    "        'LR1':(0.775),'LR2':(0.795),\"diff4\":(0.020)}\n",
    "        \n",
    "res2 = {'D1':(0.873),'D2':(0.893), \"diff1\":(0.002),\n",
    "        'GNB1':(0.838),'GNB2':(0.879),\"diff2\":(0.041),\n",
    "        'KN1':(0.870),'KN2':(0.866),\"diff3\":(0.042),\n",
    "        'LR1':(0.866),'LR2':(0.889),\"diff4\":(0.023)}\n",
    "\n",
    "classifiers1 = list(res1.keys())\n",
    "values1 = np.array(list(res1.values()))\n",
    "values2 = np.array(list(res2.values()))\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.bar(classifiers1, values1, color=colors1, width = 0.4)\n",
    "ax2.set_title('F1-score')\n",
    "ax2.bar(classifiers1, values2, color =colors2,width = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ο δείκτης 1 αποδίδεται στους ταξινομητές out of the box, ενώ ο δείκτης 2 στους βελτιστοποιημένους. Με diff συμβολίζουμε την διαφορά στην επίδοση για κάθε ζεύγος ταξινομητών. Όπως ήταν αναμενόμενο, οι ταξινομητές έπειτα απο τη βελτιστοποίηση σημειώνουν πολύ υψηλές αποδόσεις, υψηλότερες από αυτές των out of the box και για τις δύο μετρικές. Πιο συγκεκριμένα, ο ταξινομητής K Neighbors είναι αυτός με το υηλότερο score καθώς και αυτός που εμφανίζει τη μεγαλύτερη διαφορά από την out of the box εκδοχή του. Ο ταξινομητής αυτός παρουσίαζε τις περισσότερες παραμέτρους, συνεπώς εξετάστηκε για ένα ευρή πεδίο ορισμού αυτών καταλήγοντας στο βέλτιστο δυνδυασμό παραμέτρων που άγγιξε accuracy 82.2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#worst classifier: Logistic Regression\n",
    "y1_pred = best_logistic.predict(X_test)\n",
    "M1 = confusion_matrix(y_test, y1_pred)\n",
    "plot_confusion_matrix(best_logistic, X_test, y_test)\n",
    "plt.title(\"Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "#best classifier (except from dummy):\n",
    "y2_pred = best_neighbors.predict(X_test)\n",
    "M2 = confusion_matrix(y_test, y2_pred)\n",
    "plot_confusion_matrix(best_neighbors, X_test, y_test)\n",
    "plt.title(\"K Neighbors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εξετάζοντας τα παραπάνω διαγράμματα διαπιστώνουμε πως ο ταξινομητης Logistic Regression προβλέπει λάθος μόλις 28 δείγματα του τέστ set, εν αντιθέσει του K Neighbors ο οποίος προβλέπει λάθος στο σύνολο 22 δείγματα.\n",
    "<br>\n",
    "Κατά συνέπεια, ο καλύτερος ταξινομητής για το συγκεκριμένο πρόβλημα είναι ο K Neighbors. Ο Logistic Regression μπορεί να έχει  περισσότερες παραμέτερους οι οποίοι του δίνουν τη δυνατότητα να σημειώσει υψηλότερα score σε κάθε μετρική, ωστόσο αυτό δεν εγγυάται ότι θα σημειώσει τη βέλτιστη επίδοση."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Μέρος 2. Kaggle dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Επισκόπηση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Το dataset Dry-Bean, περιέχει 13,611 δείγματα φασολιών, 7 διαφορετικών κατηγοριών, 7 το σύνολο δηλαδή κλάσεων, για τα οποία λαμβάνουμε μετρήσεις για 16 διαφορετικά στοιχεία (16 features). Tα δείγματα των φασολιών είναι 12διάστατα με 4 shape forms. Στόχος είναι η βέλτιστη κατηγοριοποίηση των δειγμάτων των φασολιών, στις 7 κατηγορίες με την χρήση των ταξινομητών:\n",
    "<br>\n",
    "    - Multi-Layer Perceptron (MLP) \n",
    "<br>\n",
    "    - Support Vector Machines (SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Σε κάθε στήλη εμφανίζεται ως τίτλος το όνομα του χαρακτηριστικού. Οι γραμμές δεν ειναι αριθμημένες."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Οι ετικέτες των κλάσεων αποτυπώνονται ως strings με τα ονόματα των φασολιών και βρίσκονται στην τελευταία κολώνα με τίτλο consensus. Φροντίζουμε να μετατρέψουμε το κάθε string σε ένα ξεχωριστό αριθμό από το 0 έως και το 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ούτε στο δεδομένο dataset υπάρχουν απουσιάζουσες τιμές. Παρακάτω, βάσει των περιγραφών του Kaggle, καθώς και τους δεδομένους βοηθητικούς κώδικες, κατανοούμε καλύτερα το dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = \"Dry_Bean.csv\"\n",
    "CLASSES = np.array([\"SEKER\",\"BARBUNYA\",\"BOMBAY\",\"CALI\",\"DERMASON\",\"HOROZ\",\"SIRA\"])\n",
    "data = pd.read_csv(SOURCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>MajorAxisLength</th>\n",
       "      <th>MinorAxisLength</th>\n",
       "      <th>AspectRation</th>\n",
       "      <th>Eccentricity</th>\n",
       "      <th>ConvexArea</th>\n",
       "      <th>EquivDiameter</th>\n",
       "      <th>Extent</th>\n",
       "      <th>Solidity</th>\n",
       "      <th>roundness</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>ShapeFactor1</th>\n",
       "      <th>ShapeFactor2</th>\n",
       "      <th>ShapeFactor3</th>\n",
       "      <th>ShapeFactor4</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28395</td>\n",
       "      <td>610.291</td>\n",
       "      <td>208.178117</td>\n",
       "      <td>173.888747</td>\n",
       "      <td>1.197191</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>28715</td>\n",
       "      <td>190.141097</td>\n",
       "      <td>0.763923</td>\n",
       "      <td>0.988856</td>\n",
       "      <td>0.958027</td>\n",
       "      <td>0.913358</td>\n",
       "      <td>0.007332</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.834222</td>\n",
       "      <td>0.998724</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28734</td>\n",
       "      <td>638.018</td>\n",
       "      <td>200.524796</td>\n",
       "      <td>182.734419</td>\n",
       "      <td>1.097356</td>\n",
       "      <td>0.411785</td>\n",
       "      <td>29172</td>\n",
       "      <td>191.272751</td>\n",
       "      <td>0.783968</td>\n",
       "      <td>0.984986</td>\n",
       "      <td>0.887034</td>\n",
       "      <td>0.953861</td>\n",
       "      <td>0.006979</td>\n",
       "      <td>0.003564</td>\n",
       "      <td>0.909851</td>\n",
       "      <td>0.998430</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29380</td>\n",
       "      <td>624.110</td>\n",
       "      <td>212.826130</td>\n",
       "      <td>175.931143</td>\n",
       "      <td>1.209713</td>\n",
       "      <td>0.562727</td>\n",
       "      <td>29690</td>\n",
       "      <td>193.410904</td>\n",
       "      <td>0.778113</td>\n",
       "      <td>0.989559</td>\n",
       "      <td>0.947849</td>\n",
       "      <td>0.908774</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.825871</td>\n",
       "      <td>0.999066</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30008</td>\n",
       "      <td>645.884</td>\n",
       "      <td>210.557999</td>\n",
       "      <td>182.516516</td>\n",
       "      <td>1.153638</td>\n",
       "      <td>0.498616</td>\n",
       "      <td>30724</td>\n",
       "      <td>195.467062</td>\n",
       "      <td>0.782681</td>\n",
       "      <td>0.976696</td>\n",
       "      <td>0.903936</td>\n",
       "      <td>0.928329</td>\n",
       "      <td>0.007017</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.861794</td>\n",
       "      <td>0.994199</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30140</td>\n",
       "      <td>620.134</td>\n",
       "      <td>201.847882</td>\n",
       "      <td>190.279279</td>\n",
       "      <td>1.060798</td>\n",
       "      <td>0.333680</td>\n",
       "      <td>30417</td>\n",
       "      <td>195.896503</td>\n",
       "      <td>0.773098</td>\n",
       "      <td>0.990893</td>\n",
       "      <td>0.984877</td>\n",
       "      <td>0.970516</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.941900</td>\n",
       "      <td>0.999166</td>\n",
       "      <td>SEKER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Area  Perimeter  MajorAxisLength  MinorAxisLength  AspectRation  \\\n",
       "0  28395    610.291       208.178117       173.888747      1.197191   \n",
       "1  28734    638.018       200.524796       182.734419      1.097356   \n",
       "2  29380    624.110       212.826130       175.931143      1.209713   \n",
       "3  30008    645.884       210.557999       182.516516      1.153638   \n",
       "4  30140    620.134       201.847882       190.279279      1.060798   \n",
       "\n",
       "   Eccentricity  ConvexArea  EquivDiameter    Extent  Solidity  roundness  \\\n",
       "0      0.549812       28715     190.141097  0.763923  0.988856   0.958027   \n",
       "1      0.411785       29172     191.272751  0.783968  0.984986   0.887034   \n",
       "2      0.562727       29690     193.410904  0.778113  0.989559   0.947849   \n",
       "3      0.498616       30724     195.467062  0.782681  0.976696   0.903936   \n",
       "4      0.333680       30417     195.896503  0.773098  0.990893   0.984877   \n",
       "\n",
       "   Compactness  ShapeFactor1  ShapeFactor2  ShapeFactor3  ShapeFactor4  Class  \n",
       "0     0.913358      0.007332      0.003147      0.834222      0.998724  SEKER  \n",
       "1     0.953861      0.006979      0.003564      0.909851      0.998430  SEKER  \n",
       "2     0.908774      0.007244      0.003048      0.825871      0.999066  SEKER  \n",
       "3     0.928329      0.007017      0.003215      0.861794      0.994199  SEKER  \n",
       "4     0.970516      0.006697      0.003665      0.941900      0.999166  SEKER  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Display first 5 lines of the Dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2027 instances for class: SEKER\n",
      "There are 1322 instances for class: BARBUNYA\n",
      "There are 522 instances for class: BOMBAY\n",
      "There are 1630 instances for class: CALI\n",
      "There are 3546 instances for class: DERMASON\n",
      "There are 1928 instances for class: HOROZ\n",
      "There are 2636 instances for class: SIRA\n",
      "\n",
      "The class of beans with the least amount of instances is: BOMBAY\n"
     ]
    }
   ],
   "source": [
    "def findInstances(beans,classes):\n",
    "    instanceCount = dict()\n",
    "    for beanClass in CLASSES:\n",
    "        numinstances = beans.Class.value_counts()[beanClass]\n",
    "        instanceCount[beanClass] = numinstances\n",
    "        print(f\"There are {numinstances} instances for class: {beanClass}\")\n",
    "\n",
    "    minInstance = min(instanceCount, key=instanceCount.get)\n",
    "\n",
    "    print(f\"\\nThe class of beans with the least amount of instances is: {minInstance}\")\n",
    "    \n",
    "    \n",
    "findInstances(data,CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Μετρικές"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Είθισται η μετρική accuracy να χρησιμοποιείται όταν το dataset περιέχει περίπου ίσο αριθμό δειγμάτων για κάθε κατηγορία, ενώ αποφεύγεται όταν μία κλάση έχει σημαντικά περισσότερα δείγματα από τις υπόλοιπες. \n",
    "<br>\n",
    "Από την άλλη, η μετρική f1-score χρησιμοποιείται όταν οι False Negatives και False Positives προβλέψεις είναι αρκετές και όταν τα δείγματα κάθε κλάσης δεν είναι ισοκατανεμημένα.\n",
    "<br>\n",
    "Από τα παραπάνω αποτελέσματα διαπιστώνουμε ότι η κλάση DERMASON έχει σημαντικά περισσότερα δείγματα από τις υπόλοιπες 6, ενώ η κλάση BOMBAY διαθέτει τα λιγότερα δείγματα. \n",
    "<br>\n",
    "Οι μετρικές που θα επιλέξουμε είναι accuracy και f1-score, προκειμένου να καταλήξουμε στις παραπάνω διαπιστώσεις."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split και σχήμα CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω, χωρίζουμε τα δεδομένα μας σε train και test, ενώ συμβολίζουμε την κάθε κλάση με έναν αριθμό από το 0 μέχρι και το 6. Και σε αυτό το dataset, για την αξιολόγηση χρησιμοποιούμε το σχήμα διασταυρούμενης επικύρωσης, επιλέγοντας το 20% των δεδομένων να αποτελεί το test set. \n",
    "<br>\n",
    "Eπιλέγουμε αυτό το ποσοστό διαμοιρασμού, καθώς πλέον οι κλάσεις μας είναι αρκετές και προκειμένου το μοντέλο μας να εκπαιδευτεί καλά σε κάθε μία από αυτές, απαιτούνται περισσότερα δείγματα εκπαίδευσης. Με αυτόν τον τρόπο, το μοντέλο μας αποκτά τη δυνατότητα της γενίκευσης.\n",
    "<br>\n",
    "Eπιπλέον, εφαρμόζουμε StandardScaler στα δεδομένα μας, αφαιρούμε δηλαδή από το χαρακτηριστικό τον μέσο όρο του και κάνουμε scaling κάθε χαρακτηριστικό στην μοναδιαία διακύμανση για την επίτευξη καλύτερων προβλέψεων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split#Preprocessing Data for Training\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Using train_test_split \n",
    "dataAttributes = data.drop(\"Class\",axis=1)\n",
    "dataClasses = data[[\"Class\"]]\n",
    "\n",
    "#print(data.head())\n",
    "# setting random_state to 0 for reproducable results\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataAttributes,dataClasses, test_size = 0.2, train_size=0.8, random_state=0)\n",
    "\n",
    "# Implementing StandardScaler feature scaling\n",
    "X_train = StandardScaler().fit_transform(x_train)\n",
    "X_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "#give number to each class\n",
    "d = dict(zip(CLASSES, range(0,7)))\n",
    "y_test = y_test['Class'].map(d, na_action='ignore')\n",
    "y_train = y_train['Class'].map(d, na_action='ignore')\n",
    "\n",
    "y_train =  np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "\n",
    "X = np.append(X_train, X_test).reshape(13611,16)\n",
    "y = np.append(y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Επίδοση out-of-the-box\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_cross_val(classifier, X, y):\n",
    "    \n",
    "    acc = cross_val_score(classifier, X, y, cv=10)\n",
    "    f1 = cross_val_score(classifier, X, y, cv=10 , scoring='f1_weighted')\n",
    "    print(\"The mean accuracy for \"+ str(classifier)[:-2]+\" is: \", acc.mean(), \"\\n\", \"The F1-score for \"+ str(classifier)[:-2]+\" is:\", f1.mean(),  '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for MLPClassifier is:  0.931667358747907 \n",
      " The F1-score for MLPClassifier is: 0.9316185179559693 \n",
      "\n",
      "The mean accuracy for SVC is:  0.9274430467779398 \n",
      " The F1-score for SVC is: 0.9274685990536279 \n",
      " \n",
      "The mean accuracy for DummyClassifier is:  0.17000528344946791 \n",
      " The F1-score for DummyClassifier is: 0.170905037928529 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "svm = svm.SVC()\n",
    "perform_cross_val(mlp, X_train, y_train)\n",
    "perform_cross_val(svm, X_train, y_train)\n",
    "dummy = DummyClassifier()\n",
    "perform_cross_val(dummy, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier | Accuracy | F1-score |\n",
    "| --- | --- | --- |\n",
    "| Dummy | 0.1673 |0.1736 |\n",
    "| --- | --- | --- |\n",
    "| MLP | 0.9317 | 0.9316 |\n",
    "| --- | --- | --- |\n",
    "| SVM |0.9274| 0.9275 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "res = {'Dummy':(0.1673, 0.1736), 'MLP':(0.9317, 0.9316), 'SVM':(0.9274, 0.9275)}\n",
    "\n",
    "\n",
    "classifiers = list(res.keys())\n",
    "values = np.array(list(res.values()))\n",
    "f1score = values[:,1]   \n",
    "accur =  values[:,0]\n",
    "\n",
    "#print(f1score, accur)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n",
    "ax1.set_title('Accuracy')\n",
    "ax1.bar(classifiers, accur, color ='paleturquoise', width = 0.4)\n",
    "ax2.set_title('F1-score')\n",
    "ax2.bar(classifiers, f1score, color ='khaki',width = 0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Dummy Classifier αποδίδει πενιχρά και στις 2 μερτρικές. Πλέον, το dataset είναι σημαντικά μεγαλύτερο από αυτό του UCI και τα προβλήματα πιο σύνθετα (από binary classification μεταβήκαμε σε 7 διαφορετικές κλάσεις). Ο Dummy Classifier δεν χρησιμοποιείται σε πραγματικά προβλήματα. Τον αξιοποιούμε αποκλειστικά ως baseline, συγκρίνοντας την επίδοσή του με πραγματικούς classifiers.\n",
    "<br>\n",
    "Tοσο ο SVM όσο και ο MLP αποδίδουν άριστα στο dataset, με τον MLP να σημειώνει ελάχιστα καλύτερες επιδόσεις. Αυτό οφείλεται στην πληθώρα υπερπαραμέτρων που διαθέτει ο MLP καθιστώντας τον ιδιαίτερα πιο σύνθετο και χρονοβόρο στην εξαγωγή αποτελεσμάτων.\n",
    "<br>\n",
    "Tέλος, οι επιδόσεις και στις δύο μετρικές διαφέρουν ελάχιστα (τέταρτο δεκαδικό ψηφίο)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bελτιστοποίηση"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Προεπεξεργασία"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn import preprocessing\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def perform_preprocessing(classifier, X_train,X_test, y_test, y_train):\n",
    "        \n",
    "    selector = VarianceThreshold()\n",
    "    train_reduced = selector.fit_transform(X_train)\n",
    "    test_reduced = selector.transform(X_test)\n",
    "    \n",
    "    scaler = preprocessing.StandardScaler().fit(train_reduced)\n",
    "    train_scaled = scaler.transform(train_reduced)\n",
    "    test_scaled = scaler.transform(test_reduced)\n",
    "\n",
    "    ros = RandomOverSampler()\n",
    "    train_resampled, trainTargets_resampled = ros.fit_resample(train_scaled,y_train)\n",
    "\n",
    "    n = 3\n",
    "    pca = PCA(n_components=n)\n",
    "    trainPCA = pca.fit_transform(train_resampled)\n",
    "    testPCA = pca.transform(test_scaled)\n",
    "    \n",
    "    classifier.fit(trainPCA, trainTargets_resampled)\n",
    "    preds = classifier.predict(testPCA)\n",
    "    print(classification_report(y_test, preds))\n",
    "    acc = cross_val_score(classifier, trainPCA, trainTargets_resampled, cv=10)\n",
    "    f1 = cross_val_score(classifier, trainPCA, trainTargets_resampled, cv=10 , scoring='f1_weighted')\n",
    "    print(\"The mean accuracy for \"+ str(classifier)[:-2]+\" is: \", acc.mean(), \"\\n\", \"The F1-score for \"+ str(classifier)[:-2]+\" is:\", f1.mean(),  '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for MLPClassifier is: 0.9447075423347014 \n",
      " The F1-score for MLPClassifier is: 0.9439206692415949 \n",
      "The mean accuracy for SVC is: 0.8853995912226535\n",
      " The F1-score for SVC is: 0.8854763971388635  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "svm = svm.SVC(decision_function_shape='ovo', random_state = 0)\n",
    "\n",
    "perform_preprocessing(mlp, X_train,X_test, y_test, y_train)\n",
    "perform_preprocessing(svm, X_train,X_test, y_test, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.decomposition import PCA   \n",
    "\n",
    "def define_pipeline(classifier,X,y):\n",
    "    selector = VarianceThreshold()\n",
    "    scaler = StandardScaler()\n",
    "    ros = RandomOverSampler()\n",
    "    pca = PCA()\n",
    "    pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', ros), ('pca', pca), ('classifier', classifier)])\n",
    "    \n",
    "    acc = cross_val_score(classifier, X_train, y_train, cv=10) #X_train, y_train\n",
    "    f1 = cross_val_score(classifier, X_train, y_train, cv=10 , scoring='f1_weighted') #X_train, y_train\n",
    "    print(\"The mean accuracy for \"+ str(classifier)[:-2]+\" is: \", acc.mean(), \"\\n\", \"The F1-score for \"+ str(classifier)[:-2]+\" is:\", f1.mean(),  '\\n') \n",
    "    \n",
    "    return selector, scaler, ros, pca, pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for MLPClassifier is:  0.9276261951061416 \n",
      " The F1-score for MLPClassifier: 0.9273405932532123 \n",
      "\n",
      "The mean accuracy for SVC is:  0.8395482228704154 \n",
      " The F1-score for SVC is: 0.8331446064570285 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "svm = svm.SVC(decision_function_shape='ovo', random_state = 0)\n",
    "\n",
    "mlp_selector, mlp_scaler, mlp_ros, mlp_pca, _  = define_pipeline(mlp, X_train,y_train)\n",
    "svm_selector, svm_scaler, svm_ros, svm_pca, _ = define_pipeline(svm, X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Εύρεση βέλτιστων υπερμαραμέτρων με grid search & cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'activation': 'relu', 'alpha': 0.05, 'hidden_layer_sizes': (50, 100, 50), 'learning_rate': 'constant', 'solver': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=10)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Best parameter set\n",
    "print('Best parameters found:\\n', clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for MLP is:  0.930289526278831 \n",
      " The F1-score for MLP is: 0.930598425804598 \n"
     ]
    }
   ],
   "source": [
    "acc = cross_val_score(MLPClassifier(activation = 'relu', alpha = 0.05, hidden_layer_sizes =  (50, 100, 50),learning_rate = 'constant', solver='adam'), X_train, y_train, cv=10) \n",
    "f1 = cross_val_score(MLPClassifier(activation = 'relu', alpha = 0.05, hidden_layer_sizes =  (50, 100, 50),learning_rate = 'constant', solver='adam'), X_train, y_train, cv=10 , scoring='f1_weighted') \n",
    "print(\"The mean accuracy for MLP is: \", acc.mean(), \"\\n\", \"The F1-score for MLP is:\", f1.mean(),  '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "SVC(C=0.1, gamma=0.1, max_iter=20)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(svm.SVC(), param_grid, n_jobs=-1, cv=10)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    " \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean accuracy for SVM is:  0.9530344048776538 \n",
      " The F1-score for SVM is: 0.9731495586552845 \n"
     ]
    }
   ],
   "source": [
    "acc = cross_val_score(svm.SVC(C=0.1, gamma=0.1, kernel='rbf'), X_train, y_train, cv=10) \n",
    "f1 = cross_val_score(svm.SVC(C=0.1, gamma=0.1, kernel='rbf'), X_train, y_train, cv=10 , scoring='f1_weighted') \n",
    "print(\"The mean accuracy for SVM is: \", acc.mean(), \"\\n\", \"The F1-score for SVM is:\", f1.mean(),  '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (0.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from imbalanced-learn) (1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from imbalanced-learn) (1.7.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from imbalanced-learn) (1.19.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (3.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Using cached optuna-2.10.0-py3-none-any.whl (308 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from optuna) (20.5)\n",
      "Requirement already satisfied: scipy!=1.4.0 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from optuna) (1.7.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from optuna) (1.19.4)\n",
      "Collecting cmaes>=0.8.2\n",
      "  Using cached cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from packaging>=20.0->optuna) (2.4.7)\n",
      "Collecting sqlalchemy>=1.1.0\n",
      "  Downloading SQLAlchemy-1.4.27-cp39-cp39-win32.whl (1.5 MB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Downloading greenlet-1.1.2-cp39-cp39-win32.whl (98 kB)\n",
      "Collecting alembic\n",
      "  Using cached alembic-1.7.5-py3-none-any.whl (209 kB)\n",
      "Collecting cliff\n",
      "  Downloading cliff-3.10.0-py3-none-any.whl (80 kB)\n",
      "Collecting autopage>=0.4.0\n",
      "  Using cached autopage-0.4.0-py3-none-any.whl (20 kB)\n",
      "Collecting cmd2>=1.0.0\n",
      "  Downloading cmd2-2.3.2-py3-none-any.whl (149 kB)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
      "Requirement already satisfied: attrs>=16.3.0 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
      "Collecting pbr!=2.1.0,>=2.0.0\n",
      "  Using cached pbr-5.8.0-py2.py3-none-any.whl (112 kB)\n",
      "Collecting PrettyTable>=0.7.2\n",
      "  Using cached prettytable-2.4.0-py3-none-any.whl (24 kB)\n",
      "Collecting pyperclip>=1.6\n",
      "  Using cached pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Collecting PyYAML\n",
      "  Downloading PyYAML-6.0-cp39-cp39-win32.whl (138 kB)\n",
      "Collecting stevedore>=2.0.1\n",
      "  Using cached stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
      "Collecting colorlog\n",
      "  Using cached colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from colorlog->optuna) (0.4.4)\n",
      "Collecting Mako\n",
      "  Using cached Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\lib\\site-packages (from Mako->alembic->optuna) (1.1.1)\n",
      "Collecting pyreadline3\n",
      "  Using cached pyreadline3-3.3-py3-none-any.whl (95 kB)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "Building wheels for collected packages: pyperclip\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11112 sha256=79397374e3014c31b377728830dc8fd302d9ad03bd44c6ec2720fd923f139c9a\n",
      "  Stored in directory: c:\\users\\xrist\\appdata\\local\\pip\\cache\\wheels\\0c\\09\\9e\\49e21a6840ef7955b06d47394afef0058f0378c0914e48b8b8\n",
      "Successfully built pyperclip\n",
      "Installing collected packages: pyreadline3, pyperclip, pbr, greenlet, stevedore, sqlalchemy, PyYAML, PrettyTable, Mako, cmd2, autopage, tqdm, colorlog, cmaes, cliff, alembic, optuna\n",
      "Successfully installed Mako-1.1.6 PrettyTable-2.4.0 PyYAML-6.0 alembic-1.7.5 autopage-0.4.0 cliff-3.10.0 cmaes-0.8.2 cmd2-2.3.2 colorlog-6.6.0 greenlet-1.1.2 optuna-2.10.0 pbr-5.8.0 pyperclip-1.8.2 pyreadline3-3.3 sqlalchemy-1.4.27 stevedore-3.5.0 tqdm-4.62.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\xrist\\appdata\\local\\programs\\python\\python39-32\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U imbalanced-learn\n",
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    \n",
    "    # Load data\n",
    "    dataAttributes = data.drop(\"Class\",axis=1)\n",
    "    dataClasses = data[[\"Class\"]]\n",
    "    \n",
    "    # setting random_state to 0 for reproducable results\n",
    "    x_train, x_test, y_train, y_test = train_test_split(dataAttributes,dataClasses, test_size = 0.2, train_size=0.8, random_state=0)\n",
    "    \n",
    "    \n",
    "    # Implementing StandardScaler feature scaling\n",
    "    X_train = StandardScaler().fit_transform(x_train)\n",
    "    X_test = StandardScaler().fit_transform(x_test)\n",
    "\n",
    "    d = dict(zip(CLASSES, range(0,7)))\n",
    "    y_test = y_test['Class'].map(d, na_action='ignore')\n",
    "    y_train = y_train['Class'].map(d, na_action='ignore')\n",
    "\n",
    "    y_train =  np.ravel(y_train)\n",
    "    y_test = np.ravel(y_test)\n",
    "    \n",
    "    X = np.append(X_train, X_test).reshape(13611,16)\n",
    "    y = np.append(y_train, y_test)\n",
    "\n",
    "    # Sample hyper parameters\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"MLPClassifier\",\n",
    "                                                               \"SVC\"])\n",
    "    if classifier_name==\"MLPClassifier\":\n",
    "\n",
    "        # Sample hyper parameters\n",
    "        activation = trial.suggest_categorical('activation', [\"identity\", \"logistic\", \"tanh\", \"relu\"])\n",
    "        solver = trial.suggest_categorical(\"solver\", \n",
    "                                              [\"sgd\", \"adam\"])\n",
    "        tol = trial.suggest_int('tol', 1e-8,1e-1, 1e-7)\n",
    "        learning_rate = trial.suggest_categorical('learning_rate', \n",
    "                                           [\"constant\",\"invscaling\"])\n",
    "        # Construct the model\n",
    "        clf = MLPClassifier(activation=activation,\n",
    "                               solver=solver,\n",
    "                               tol=tol,\n",
    "                               learning_rate=learning_rate\n",
    "                               \n",
    "                               )\n",
    "    elif classifier_name==\"SVC\":\n",
    "\n",
    "        # Sample hyper parameters\n",
    "        C = trial.suggest_loguniform('C', 1e-10, 1)\n",
    "        kernel = trial.suggest_categorical('kernel',['poly','rbf','sigmoid'])\n",
    "        degree = trial.suggest_int('degree',1, 50)\n",
    "        gamma = trial.suggest_loguniform('gamma',0.001,10000)\n",
    "\n",
    "        # Construct the model\n",
    "        clf = SVC(C=C, kernel=kernel, degree=degree,gamma=gamma)\n",
    "    \n",
    "    # Train the model\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    loss = mean_squared_error(y_test,y_pred_test)\n",
    "\n",
    "    print(\"Test Score:\",clf.score(X_test,y_test))\n",
    "    print(\"Train Score:\",clf.score(X_train,y_train))\n",
    "    \n",
    "    print(\"\\n=================\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:16,810]\u001b[0m A new study created in memory with name: no-name-4af72568-7be0-4795-8786-e1a78705d967\u001b[0m\n",
      "\u001b[32m[I 2021-11-28 04:26:18,720]\u001b[0m Trial 0 finished with value: 1.5600440690414983 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.757253029746603\n",
      "Train Score: 0.7341109478324761\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:19,055]\u001b[0m Trial 1 finished with value: 9.473007712082262 and parameters: {'classifier': 'SVC', 'C': 2.0217718263421177e-10, 'kernel': 'poly', 'degree': 22, 'gamma': 1.2029913721913787}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.23466764597869996\n",
      "Train Score: 0.23218221895664953\n",
      "\n",
      "=================\n",
      "Test Score: 0.51120088138083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:20,434]\u001b[0m Trial 2 finished with value: 6.514873301505692 and parameters: {'classifier': 'SVC', 'C': 4.9898075934414093e-05, 'kernel': 'sigmoid', 'degree': 17, 'gamma': 0.4536479747508731}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.4829169728141073\n",
      "\n",
      "=================\n",
      "Test Score: 0.5993389643775248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:21,745]\u001b[0m Trial 3 finished with value: 6.215938303341902 and parameters: {'classifier': 'SVC', 'C': 0.002182362377366676, 'kernel': 'sigmoid', 'degree': 16, 'gamma': 0.004339229613651419}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.5993754592211609\n",
      "\n",
      "=================\n",
      "Test Score: 0.7858979067205288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:22,998]\u001b[0m Trial 4 finished with value: 3.4124127800220347 and parameters: {'classifier': 'SVC', 'C': 0.831244643030328, 'kernel': 'rbf', 'degree': 34, 'gamma': 0.008585066072140638}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.7782880235121235\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:25,347]\u001b[0m Trial 5 finished with value: 2.1226588321704 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.591626882115314\n",
      "Train Score: 0.5870683321087435\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:30,625]\u001b[0m Trial 6 finished with value: 1.8461255967682704 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6577304443628351\n",
      "Train Score: 0.6540227773695811\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:33,426]\u001b[0m Trial 7 finished with value: 4.230260741828865 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.2699228791773779\n",
      "Train Score: 0.2581741366642175\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:34,179]\u001b[0m Trial 8 finished with value: 9.302240176276166 and parameters: {'classifier': 'SVC', 'C': 1.5223541088614474e-09, 'kernel': 'poly', 'degree': 28, 'gamma': 0.001982518830080877}. Best is trial 0 with value: 1.5600440690414983.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.204186558942343\n",
      "Train Score: 0.22446730345334312\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:36,943]\u001b[0m Trial 9 finished with value: 0.6426735218508998 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 9 with value: 0.6426735218508998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9236136614028645\n",
      "Train Score: 0.9212894930198383\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:40,524]\u001b[0m Trial 10 finished with value: 0.6827029012118987 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 9 with value: 0.6426735218508998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9254498714652957\n",
      "Train Score: 0.922850844966936\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:42,436]\u001b[0m Trial 11 finished with value: 0.6529562982005142 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 9 with value: 0.6426735218508998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.922879177377892\n",
      "Train Score: 0.9216568699485672\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:44,320]\u001b[0m Trial 12 finished with value: 0.6966580976863753 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 9 with value: 0.6426735218508998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9236136614028645\n",
      "Train Score: 0.9225753122703895\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:46,191]\u001b[0m Trial 13 finished with value: 0.6599338964377525 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 9 with value: 0.6426735218508998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9225119353654058\n",
      "Train Score: 0.9226671565025716\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:47,985]\u001b[0m Trial 14 finished with value: 0.663973558575101 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 9 with value: 0.6426735218508998.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.922879177377892\n",
      "Train Score: 0.919911829537105\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:49,908]\u001b[0m Trial 15 finished with value: 0.5277267719427102 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9327947117150202\n",
      "Train Score: 0.9284533431300515\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:53,441]\u001b[0m Trial 16 finished with value: 0.5501285347043702 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9309585016525891\n",
      "Train Score: 0.9275349008082292\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:26:58,399]\u001b[0m Trial 17 finished with value: 0.6323907455012854 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9291222915901579\n",
      "Train Score: 0.9279022777369581\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:02,142]\u001b[0m Trial 18 finished with value: 0.5339698861549761 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9331619537275064\n",
      "Train Score: 0.9279941219691403\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:06,516]\u001b[0m Trial 19 finished with value: 0.5464561145795079 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9353654058024238\n",
      "Train Score: 0.9272593681116826\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:11,166]\u001b[0m Trial 20 finished with value: 0.5398457583547558 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9309585016525891\n",
      "Train Score: 0.9271675238795004\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:15,868]\u001b[0m Trial 21 finished with value: 0.5975027543150937 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9294895336026442\n",
      "Train Score: 0.9279941219691403\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:20,139]\u001b[0m Trial 22 finished with value: 0.5317664340800587 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9320602276900477\n",
      "Train Score: 0.9267083027185893\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:25,055]\u001b[0m Trial 23 finished with value: 0.5582078589790672 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9313257436650753\n",
      "Train Score: 0.9275349008082292\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:33,657]\u001b[0m Trial 24 finished with value: 0.6184355490268086 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9280205655526992\n",
      "Train Score: 0.9259735488611315\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:36,084]\u001b[0m Trial 25 finished with value: 0.6132941608520015 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9291222915901579\n",
      "Train Score: 0.927443056576047\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:38,095]\u001b[0m Trial 26 finished with value: 0.6019096584649284 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9298567756151304\n",
      "Train Score: 0.9278104335047759\n",
      "\n",
      "=================\n",
      "Test Score: 0.23466764597869996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:38,652]\u001b[0m Trial 27 finished with value: 9.291590157914065 and parameters: {'classifier': 'SVC', 'C': 1.743285673090127e-07, 'kernel': 'rbf', 'degree': 48, 'gamma': 2931.2909314548842}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.25\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:42,754]\u001b[0m Trial 28 finished with value: 0.7150201983106867 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9162688211531399\n",
      "Train Score: 0.9072373254959588\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:51,225]\u001b[0m Trial 29 finished with value: 0.6338597135512303 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9287550495776716\n",
      "Train Score: 0.9247795738427627\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:55,362]\u001b[0m Trial 30 finished with value: 0.5993389643775248 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9302240176276166\n",
      "Train Score: 0.926983835415136\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:27:57,966]\u001b[0m Trial 31 finished with value: 0.5886889460154242 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9298567756151304\n",
      "Train Score: 0.926983835415136\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:01,532]\u001b[0m Trial 32 finished with value: 0.6165993389643776 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9291222915901579\n",
      "Train Score: 0.9279022777369581\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:05,091]\u001b[0m Trial 33 finished with value: 0.6008079324274697 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9309585016525891\n",
      "Train Score: 0.9275349008082292\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:05,353]\u001b[0m Trial 34 finished with value: 2.3815644509731912 and parameters: {'classifier': 'SVC', 'C': 0.7867511714405819, 'kernel': 'poly', 'degree': 1, 'gamma': 5001.553813763268}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.6636063165626148\n",
      "Train Score: 0.681208670095518\n",
      "\n",
      "=================\n",
      "Test Score: 0.2467866323907455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:06,396]\u001b[0m Trial 35 finished with value: 9.070510466397355 and parameters: {'classifier': 'SVC', 'C': 3.676890859047155e-07, 'kernel': 'sigmoid', 'degree': 50, 'gamma': 61.61329676707771}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.24687729610580456\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:08,327]\u001b[0m Trial 36 finished with value: 0.6331252295262578 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.927653323540213\n",
      "Train Score: 0.9278104335047759\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:11,101]\u001b[0m Trial 37 finished with value: 0.5457216305545355 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9320602276900477\n",
      "Train Score: 0.9265246142542248\n",
      "\n",
      "=================\n",
      "Test Score: 0.4663973558575101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:12,241]\u001b[0m Trial 38 finished with value: 4.211531399192068 and parameters: {'classifier': 'SVC', 'C': 0.0007950407945934473, 'kernel': 'rbf', 'degree': 3, 'gamma': 106.24176118498586}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.4670279206465834\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:14,417]\u001b[0m Trial 39 finished with value: 0.6683804627249358 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9170033051781123\n",
      "Train Score: 0.9093497428361499\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:18,271]\u001b[0m Trial 40 finished with value: 0.6066838046272494 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9313257436650753\n",
      "Train Score: 0.9272593681116826\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:21,438]\u001b[0m Trial 41 finished with value: 0.622107969151671 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 15 with value: 0.5277267719427102.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9280205655526992\n",
      "Train Score: 0.9268001469507715\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:26,351]\u001b[0m Trial 42 finished with value: 0.5251560778553066 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9331619537275064\n",
      "Train Score: 0.9268919911829537\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:31,234]\u001b[0m Trial 43 finished with value: 0.7601909658464928 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9136981270657363\n",
      "Train Score: 0.904757531227039\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:39,700]\u001b[0m Trial 44 finished with value: 0.6327579875137715 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9283878075651855\n",
      "Train Score: 0.9243203526818515\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:43,444]\u001b[0m Trial 45 finished with value: 1.615864854939405 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.7807565185457216\n",
      "Train Score: 0.7580822924320353\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:43,893]\u001b[0m Trial 46 finished with value: 8.886889460154242 and parameters: {'classifier': 'SVC', 'C': 3.636393634890015e-08, 'kernel': 'poly', 'degree': 40, 'gamma': 0.10403602441545043}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.25853837679030484\n",
      "Train Score: 0.2607457751653196\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:48,689]\u001b[0m Trial 47 finished with value: 0.5468233565919941 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9320602276900477\n",
      "Train Score: 0.926983835415136\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:53,632]\u001b[0m Trial 48 finished with value: 0.5449871465295629 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9298567756151304\n",
      "Train Score: 0.9259735488611315\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:58,307]\u001b[0m Trial 49 finished with value: 0.6345941975762027 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9239809034153507\n",
      "Train Score: 0.9216568699485672\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:28:59,897]\u001b[0m Trial 50 finished with value: 0.6867425633492471 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9199412412780023\n",
      "Train Score: 0.9176157237325496\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:03,859]\u001b[0m Trial 51 finished with value: 0.604480352552332 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9302240176276166\n",
      "Train Score: 0.927443056576047\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:08,668]\u001b[0m Trial 52 finished with value: 0.6136614028644877 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9287550495776716\n",
      "Train Score: 0.927443056576047\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:13,678]\u001b[0m Trial 53 finished with value: 0.5861182519280206 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9316929856775615\n",
      "Train Score: 0.927443056576047\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:18,645]\u001b[0m Trial 54 finished with value: 0.5633492471538744 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9316929856775615\n",
      "Train Score: 0.9289125642909625\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:22,992]\u001b[0m Trial 55 finished with value: 0.5897906720528828 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9320602276900477\n",
      "Train Score: 0.9279022777369581\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:24,466]\u001b[0m Trial 56 finished with value: 0.6169665809768637 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9243481454278369\n",
      "Train Score: 0.9232182218956649\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:29,271]\u001b[0m Trial 57 finished with value: 0.5952993022401762 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9298567756151304\n",
      "Train Score: 0.9267083027185893\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:33,935]\u001b[0m Trial 58 finished with value: 0.6885787734116783 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9214102093279471\n",
      "Train Score: 0.9211976487876561\n",
      "\n",
      "=================\n",
      "Test Score: 0.35438854204921044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:35,174]\u001b[0m Trial 59 finished with value: 6.940874035989717 and parameters: {'classifier': 'SVC', 'C': 0.0028542256725706157, 'kernel': 'sigmoid', 'degree': 10, 'gamma': 14.392412840438276}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.3570903747244673\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:43,567]\u001b[0m Trial 60 finished with value: 0.6033786265148733 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9291222915901579\n",
      "Train Score: 0.9244121969140338\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:47,693]\u001b[0m Trial 61 finished with value: 0.5842820418655894 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9316929856775615\n",
      "Train Score: 0.9275349008082292\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:52,641]\u001b[0m Trial 62 finished with value: 0.5809768637532133 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9302240176276166\n",
      "Train Score: 0.9278104335047759\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:54,565]\u001b[0m Trial 63 finished with value: 0.5780389276533235 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9305912596401028\n",
      "Train Score: 0.9277185892725937\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:56,458]\u001b[0m Trial 64 finished with value: 0.5651854572163055 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9320602276900477\n",
      "Train Score: 0.9286370315944159\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:29:58,400]\u001b[0m Trial 65 finished with value: 0.5420492104296731 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9294895336026442\n",
      "Train Score: 0.9259735488611315\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:00,327]\u001b[0m Trial 66 finished with value: 0.5486595666544253 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9316929856775615\n",
      "Train Score: 0.9272593681116826\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:02,271]\u001b[0m Trial 67 finished with value: 0.5629820051413882 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.932427469702534\n",
      "Train Score: 0.9276267450404114\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:03,750]\u001b[0m Trial 68 finished with value: 0.6779287550495777 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'adam', 'tol': 0, 'learning_rate': 'invscaling'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9217774513404333\n",
      "Train Score: 0.9211058045554739\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:05,681]\u001b[0m Trial 69 finished with value: 0.6500183621006244 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9272860815277267\n",
      "Train Score: 0.9270756796473182\n",
      "\n",
      "=================\n",
      "Test Score: 0.6702166727873669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:06,310]\u001b[0m Trial 70 finished with value: 3.839515240543518 and parameters: {'classifier': 'SVC', 'C': 3.8078783453082252e-06, 'kernel': 'rbf', 'degree': 39, 'gamma': 437.7651894855179}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.6735855988243938\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:10,158]\u001b[0m Trial 71 finished with value: 0.525890561880279 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9313257436650753\n",
      "Train Score: 0.9272593681116826\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:14,712]\u001b[0m Trial 72 finished with value: 0.5339698861549761 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9331619537275064\n",
      "Train Score: 0.9262490815576782\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:18,449]\u001b[0m Trial 73 finished with value: 0.5699596033786265 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.932427469702534\n",
      "Train Score: 0.9271675238795004\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:22,374]\u001b[0m Trial 74 finished with value: 0.6011751744399559 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9291222915901579\n",
      "Train Score: 0.9264327700220426\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:27,296]\u001b[0m Trial 75 finished with value: 0.6320235034887991 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9287550495776716\n",
      "Train Score: 0.9279022777369581\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:32,044]\u001b[0m Trial 76 finished with value: 0.525890561880279 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9327947117150202\n",
      "Train Score: 0.9276267450404114\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:40,423]\u001b[0m Trial 77 finished with value: 0.6933529195739992 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9214102093279471\n",
      "Train Score: 0.915686994856723\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:43,936]\u001b[0m Trial 78 finished with value: 0.5930958501652589 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9327947117150202\n",
      "Train Score: 0.9278104335047759\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:48,757]\u001b[0m Trial 79 finished with value: 0.5446199045170768 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9313257436650753\n",
      "Train Score: 0.926983835415136\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:51,097]\u001b[0m Trial 80 finished with value: 0.6305545354388542 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9291222915901579\n",
      "Train Score: 0.9266164584864071\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:54,988]\u001b[0m Trial 81 finished with value: 0.6470804260007345 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9294895336026442\n",
      "Train Score: 0.926983835415136\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:30:59,844]\u001b[0m Trial 82 finished with value: 0.5945648182152038 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9302240176276166\n",
      "Train Score: 0.9267083027185893\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:01,758]\u001b[0m Trial 83 finished with value: 0.5941975762027176 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9320602276900477\n",
      "Train Score: 0.9279941219691403\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:06,016]\u001b[0m Trial 84 finished with value: 0.5784061696658098 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9305912596401028\n",
      "Train Score: 0.9271675238795004\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:10,544]\u001b[0m Trial 85 finished with value: 0.6782959970620639 and parameters: {'classifier': 'MLPClassifier', 'activation': 'logistic', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9210429673154609\n",
      "Train Score: 0.9202792064658339\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:15,461]\u001b[0m Trial 86 finished with value: 0.5828130738156445 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9294895336026442\n",
      "Train Score: 0.926983835415136\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:20,327]\u001b[0m Trial 87 finished with value: 0.7392581711347778 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'sgd', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9166360631656262\n",
      "Train Score: 0.9099926524614255\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:20,776]\u001b[0m Trial 88 finished with value: 9.147264047006978 and parameters: {'classifier': 'SVC', 'C': 0.0378363370153812, 'kernel': 'poly', 'degree': 29, 'gamma': 0.0350939128613358}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.2713918472273228\n",
      "Train Score: 0.2726855253490081\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:25,482]\u001b[0m Trial 89 finished with value: 0.5831803158281308 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9302240176276166\n",
      "Train Score: 0.9279941219691403\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:29,163]\u001b[0m Trial 90 finished with value: 0.6786632390745502 and parameters: {'classifier': 'MLPClassifier', 'activation': 'identity', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9210429673154609\n",
      "Train Score: 0.9196362968405584\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:33,801]\u001b[0m Trial 91 finished with value: 0.5644509731913331 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9294895336026442\n",
      "Train Score: 0.9291880969875091\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:38,795]\u001b[0m Trial 92 finished with value: 0.5666544252662504 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9283878075651855\n",
      "Train Score: 0.927443056576047\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:43,138]\u001b[0m Trial 93 finished with value: 0.5945648182152038 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9302240176276166\n",
      "Train Score: 0.9279941219691403\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:45,027]\u001b[0m Trial 94 finished with value: 0.5769372016158648 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9291222915901579\n",
      "Train Score: 0.9283614988978692\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:47,767]\u001b[0m Trial 95 finished with value: 0.5361733382298935 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9309585016525891\n",
      "Train Score: 0.9284533431300515\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:53,766]\u001b[0m Trial 96 finished with value: 0.6143958868894601 and parameters: {'classifier': 'MLPClassifier', 'activation': 'tanh', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9280205655526992\n",
      "Train Score: 0.9243203526818515\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:31:56,024]\u001b[0m Trial 97 finished with value: 0.5776716856408373 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9313257436650753\n",
      "Train Score: 0.9268001469507715\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:32:00,160]\u001b[0m Trial 98 finished with value: 0.6022769004774147 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9316929856775615\n",
      "Train Score: 0.9277185892725937\n",
      "\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-28 04:32:03,569]\u001b[0m Trial 99 finished with value: 0.6143958868894601 and parameters: {'classifier': 'MLPClassifier', 'activation': 'relu', 'solver': 'adam', 'tol': 0, 'learning_rate': 'constant'}. Best is trial 42 with value: 0.5251560778553066.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 0.9316929856775615\n",
      "Train Score: 0.927443056576047\n",
      "\n",
      "=================\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# depending on the definition of objective\n",
    "# we can create study object with either minimize or maximize\n",
    "study = optuna.create_study(direction='minimize')\n",
    "\n",
    "# start tuning for the hyper-parameters\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Τεκμηρίωση Διαδικασίας"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εκκινώντας από το κάθε μοντέλο όπως έχει, δίχως δηλαδή να τροποποιήσουμε τις παραμέτρους του, ελέγχουμε την απόδοσή του στο σύνολο της εκπαίδευσης. Εξαρχής, οι ταξινομητές MLP & SVC παρουσίαζαν υψηλές αποδόσεις. Εν συνεχεία, εφαρμόζουμε τη μέθοδο της βελτιστοποίησης. Αυτή συνοψίζεται στα βήματα προεπεξεργασίας, pipeline και εύρεσης βέλτιστων παραμέτρων. \n",
    "<br>\n",
    "\n",
    "Κατά την προεπεξεργασία, εφόσον έχουμε αποκλείσει τιμές οι οποίες απουσιάζουν, μειώνουμε τις διαστάσεις εισόδου με επιλογή χαρακτηριστικών. Συγκεκριμένα, χρησιμοποιούμε τη τεχνική ελαχίστου κατωφλίου της διακύμανσης (Variance threshold), αφού αν η διακύμανση ενός χαρακτηριστικού εισόδου είναι πολύ χαμηλή, δεν μπορεί να προσφέρει σημαντικά στη διαχωριστική ικανότητα του ταξινομητή. \n",
    "<br>\n",
    "Έπειτα, κανονικοποιούμε τα χαρακτηριστικά (preprocessing.scale). Η κανονικοποίηση μετασχηματίζει τις τιμές των χαρακτηριστικών ώστε να περιοριστούν  οι πολύ μεγάλες διαφορές στις απόλυτες τιμές των χαρακτηριστικών.\n",
    "<br>\n",
    "Επειδή το dataset δεν ήταν ισορροπημένο, κάναμε oversampling προκειμένου να το εξισορροπήσουμε (ros.fit_resample).\n",
    "<br>\n",
    "Tέλος, εφαρμόζουμε ανάλυση σε κύριες συνιστώσες με την τεχνική PCA, για την μείωση της διαστατικότητας. Η διαδικασία της προεπεξεργασίας αξιολογείται και στο σύνολο της εκπαίδευσης, βάσει των δύο μετρικών.\n",
    "<br>\n",
    "\n",
    "Με τη διαδικασία του pipeline κατασκευάζουμε μια σεiρα μετασχηματιστών πάνω στα χαρακτηριστικά των δεδομένων. Το pipeline ολοκληρώνεται με έναν ταξινομητή. Φτιάχνουμε δύο ξεχωριστα pipelines ένα για SVC και ένα για MLP. Το pipeline θεωρείται συνολικά ως εκτιμητής. Συνεπώς, αξιολογείται στο σύνολο της εκπαίδευσης.\n",
    "<br>\n",
    "\n",
    "Για την επιλογή των βέλτιστων παραμέτρων χρησιμοποιούμε την βιβλιοθήκη OPTUNA. Αυτή μας επιστρέφει τη βέλτιστη αρχιτεκτονική, τον συνδυασμό δηλαδή των παραμέτρων που αποδίδουν το πιο αποδοτικό μοντέλο."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Παρουσίαση Αποτελεσμάτων"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Classifier | Accuracy | F1-score | otb Accuracy |otb F1-score |Accuracy in test set|\n",
    "| --- | --- | --- |--- | --- |--- |\n",
    "| MLP | 0.9617 | 0.9877 |+0.0300 |+0.0561|0.9237 |\n",
    "| --- | --- | --- |--- | --- |--- | --- |--- |\n",
    "| SVM | 0.9530 | 0.9731 |+0.0256 | +0.0456|0.8693|\n",
    " |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στον παραπάνω πίνακα παρουσιάζουμε στην στήλη Accuracy, το accuracy του βέλτιστου μοντέλου (έπειτα από την αρχιτεκτονική που προτείνει το grid search). Ομοίως και για την στήλη του F1-score. Τα otb Accuracy & otb F1-score αποδίδουν τη διαφορά του βέλτιστου μοντέλου συγκριτικά με το out of the box μοντέλο, για την κάθε μετρική αντίστοιχα. Τέλος, με την βιβλιοθήκη OPTUNA εξάγουμε το βέλτιστο μοντέλο και ελέγχουμε τις τιμές του accuracy στο test set. Tα αποτελέσματα αυτά αποδίδονται στην τελική στήλη του πίνακα.\n",
    "<br>\n",
    "Όσο αφορά την υψηλη απόδοση των ταξινομητών, το δίκτυο MLP συντίθεται από ένα σύνολο\n",
    "αισθητήρων (πηγαίοι κόμβοι), που αποτελούν το επίπεδο εισόδου, ένα ή περισσότερα κρυφά επίπεδα\n",
    "(hidden-layers) και ένα επίπεδο εξόδων. Τα κρυφά επίπεδα και το επίπεδο εξόδου, αποτελούν\n",
    "υπολογιστικοί κόμβοι, δηλαδή εκεί πραγματοποιούνται οι πράξεις για τον υπολογισμό της τελικής\n",
    "τιμής εξόδου, που το δίκτυο παράγει. Κύριο χαρακτηριστικό της δομής των δικτύων πολλών επιπέδων,\n",
    "είναι ότι οι νευρώνες οποιουδήποτε στρώματος l, τροφοδοτούν αποκλειστικά τους νευρώνες του\n",
    "επόμενου στρώματος l+1 και λαμβάνουν πληροφορίες, μόνο από τους νευρώνες του προηγούμενου\n",
    "στρώματος l-1. Σημαντική ιδιότητα των MLP αποτελεί η ενσωμάτωση της σιγμοειδούς συνάρτησης. Τα δίκτυα αυτά, έχουν την\n",
    "ικανότητα να προσεγγίζουν οποιαδήποτε συνεχή συνάρτηση όσο το επιθυμητό κοντά, με μόλις δύο\n",
    "επίπεδα και γι αυτό ονομάζονται καθολικοί προσεγγιστές. \n",
    "<br>\n",
    "Mε την χρήση των SVM's η  κατηγοριοποίηση των δεδομένων στηρίζεται στην εύρεση ενός βέλτιστου υπερεπιπέδου που διαχωρίζει τα δεδομένα δημιουργώντας το μέγιστο\n",
    "περιθώριο. Στην περίπτωση που ο γραμμικός διαχωρισμός είναι αδύνατος, γίνεται\n",
    "χρήση κατάλληλων απεικονίσεων που μεταφέρουν το σύνολο των δεδομένων σε\n",
    "μεγαλύτερη διάσταση ώστε να επιτευχθεί τελικά ο διαχωρισμός τους. Στα πλεονεκτήματα της μεθόδου συγκαταλλέγονται το ότι το πρόβλημα βελτιστοποίησης, λόγω\n",
    "κυρτότητας, παρουσιάζει ολικό ελάχιστο δίνοντας μοναδική βέλτιστη\n",
    "επιλογή και η σημαντική ικανότητα γενίκευσης σε μη γραμμικά\n",
    "διαχωρίσιμα δεδομένα ενσωματώνοντας το τέχνασμα του πυρήνα\n",
    "(kernel trick). Με την εφαρμογή συναρτήσεων πυρήνα είναι δυνατή η\n",
    "παραγωγή μη γραμμικών μοντέλων που οδηγούν σε γραμμικότητα σε\n",
    "χώρους μεγαλύτερων διαστάσεων. Τα παραπάνω συνοδεύονται ορισμένες φορές με το κόστος του αυξημένου χρόνου εκπαίδευσης.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για την καύτερη αντίληψη των λαθών, αποδίδουμε τους confusion matrices για τον κάθε ταξινομητή. Παρακάτω γίνεται αισθητή η υπεροχή του Multi-Layer Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#best classifier: preprocessing Logistic Regression\n",
    "mlp=MLPClassifier(activation = 'logistic', solver= 'adam', tol= 0, learning_rate = 'constant')\n",
    "mlp.fit(X_train,y_train)\n",
    "y1_pred = mlp.predict(X_test)\n",
    "M1 = confusion_matrix(y_test, y1_pred)\n",
    "plot_confusion_matrix(mlp, X_test, y_test)\n",
    "plt.title(\"MLP\")\n",
    "plt.show()\n",
    "\n",
    "#worst classifier (except from dummy):\n",
    "svm = SVC(C = 0.002, kernel= 'rbf', degree= 27, gamma= 0.011)\n",
    "svm.fit(X_train,y_train)\n",
    "y2_pred = svm.predict(X_test)\n",
    "M2 = confusion_matrix(y_test, y2_pred)\n",
    "plot_confusion_matrix(svm, X_test, y_test)\n",
    "plt.title(\"SVM\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
